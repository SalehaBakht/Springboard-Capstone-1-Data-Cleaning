{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Nine', 'Toscano Black', 'Houseblend', 'Nature', 'Organic Dark',\n",
       "       'One Hundred', 'Blend', 'Lago di Como, Blu', 'Blend No. 1',\n",
       "       'Philly Blend, 5 plantations', 'Kendari', 'Tarakan', 'Maragda',\n",
       "       'Sensations Intense', 'Zorzal Reserva, 2015 H., Kerchner', 'Noir',\n",
       "       'Ilblend', 'Red Vanilla', 'Supremo- SF', 'Dark',\n",
       "       'Epique, Blend No. 49', 'Coucher du Soleil', 'Lever du Soleil',\n",
       "       'Onyx', 'Nocturne', 'Complexite', 'Special Maker Reserve',\n",
       "       'Quetzalcoatl', 'Tsaranta', 'Semisweet', 'Campesino w/ nibs',\n",
       "       'Trinitario', 'Downtown London', 'Africa meets Latina', 'Amazonas',\n",
       "       'one hundred', 'Kuruba', 'Orinoco', 'Excellence (US Version)',\n",
       "       'Cacao Nib Crunch', 'Brooklyn Blend', 'Carre Amer',\n",
       "       'Carre Grand Noir', 'Noir Infini',\n",
       "       'Grand Cru Blend No.1, 5 yr. Anniversary Ed', 'Signature Blend',\n",
       "       'Raw', 'Mid Mountain, 2014', '100 percent', 'Latino', 'Nibby',\n",
       "       'Extra Dark', 'Bittersweet', 'Wasatch', \"Chef's Blend\",\n",
       "       'TCHOPro 60.5', 'TCHOPro 68', 'Andoa, Grand Cru blend', 'Caraque',\n",
       "       'Le Noir Extra Amer', 'House Blend, Batch 2', 'Goddess Blend',\n",
       "       'Amazonas Frucht', 'Indianer, Raw'], dtype=object)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "df1 = pd.read_csv('flavors_of_cacao.csv')\n",
    "#Explore head\n",
    "df1.head().T\n",
    "\n",
    "#Explore superficially the entire dataframe.\n",
    "df1\n",
    "\n",
    "#We can see some indexes have breaks in their names. We will rename them for ease.\n",
    "original_colnames = df1.columns\n",
    "new_colnames = ['Company', 'Specific Bean Origin or Bar Name', 'REF', 'Review Date', 'Cocoa Percent', 'Company Location', 'Rating', 'Bean Type', 'Broad Bean Origin']\n",
    "df1 = df1.rename(columns=dict(zip(original_colnames, new_colnames)))\n",
    "df1.head().T\n",
    "\n",
    "#Check all columns for null values\n",
    "df1['Company'].isnull().value_counts()\n",
    "\n",
    "df1['Specific Bean Origin or Bar Name'].isnull().value_counts()\n",
    "\n",
    "df1['REF'].isnull().value_counts()\n",
    "\n",
    "df1['Review Date'].isnull().value_counts()\n",
    "\n",
    "df1['Cocoa Percent'].isnull().value_counts()\n",
    "\n",
    "df1['Company Location'].isnull().value_counts()\n",
    "\n",
    "df1['Rating'].isnull(). value_counts()\n",
    "\n",
    "df1['Bean Type'].isnull().value_counts()\n",
    "#Notice that the results for this say there is only one null value. Visual inspection shows that there are many empty cells in the column. \n",
    "\n",
    "df1['Broad Bean Origin'].isnull().value_counts()\n",
    "#Notice that the results for this say there is only one null value. Visual inspection shows that there are many empty cells in the column. \n",
    "\n",
    "\n",
    "#Replace the missing value with the value in the corresponding Specific Bean Origin or Bar Name value instead.\n",
    "df1['Broad Bean Origin'] = df1['Broad Bean Origin'].fillna(df1['Specific Bean Origin or Bar Name'])\n",
    "df1['Broad Bean Origin'].isnull().value_counts()\n",
    "#value_counts() says there are no more null values in the column. Visual inspection of the Broad Bean Origin column in df1 still shows empty cells.\n",
    "\n",
    "#Look at most frequent Bean Type and Broad Bean Origin\n",
    "df1['Bean Type'].value_counts().head(10)\n",
    "#Note that there are 887 values that are ' '.\n",
    "\n",
    "df1['Broad Bean Origin'].value_counts().head(10)\n",
    "#Note that there are 73 values that are ' '.\n",
    "\n",
    "#Now that we know that most of the columns are complete, we will explore the existing content of those columns before trying to create content in the columns that are missing values, namely the Bean Type and Broad Bean Origin columns.\n",
    "df1['Company'].sort_values().unique()\n",
    "#Notice that there are two types of 'Artisan du Chocolat', 'Black River' appears to be a subset of A. Morin, there are several names that have Tulicorp bracketed but Tulicorp is not its own option. There do not appear to be any spelling mistakes so we will leave this for now.\n",
    "\n",
    "df1['Specific Bean Origin or Bar Name'].sort_values().unique()\n",
    "#Too many to list. From what is shown though, some chocolate bars come with lower case bar names, which is unlikely to be true.\n",
    "\n",
    "#Check that everything in REF is a number.\n",
    "df1['REF'].dtypes\n",
    "\n",
    "#Check that all Review Dates are 4 digit numbers.\n",
    "df1['Review Date'].dtypes\n",
    "\n",
    "#Convert the Cocoa Percent values to floating decimals.\n",
    "df1['Cocoa Percent'].dtypes\n",
    "\n",
    "df1['Cocoa Percent'] = df1['Cocoa Percent'].str.replace('%','').astype(float)/100\n",
    "\n",
    "df1['Cocoa Percent'].dtypes\n",
    "\n",
    "#Check spelling for Company Location values.\n",
    "df1['Company Location'].sort_values().unique()\n",
    "\n",
    "#Domincan Republic (Dominican Republic), Eucador (Ecuador), Niacragua (Nicaragua) are spelt wrong. Amsterdam is the capital of the Netherlands.\n",
    "df1['Company Location'] = df1['Company Location']\\\n",
    ".str.replace('Domincan Republic', 'Dominican Republic')\\\n",
    ".str.replace('Eucador', 'Ecuador')\\\n",
    ".str.replace('Amsterdam', 'Netherlands')\\\n",
    ".str.replace('Niacragua', 'Nicaragua')\n",
    "\n",
    "df1['Company Location'].sort_values().unique()\n",
    "\n",
    "#Check that all characters for Rating are numbers or decimals.\n",
    "df1['Rating'].dtypes\n",
    "\n",
    "#Check the spelling of Bean Type values.\n",
    "df1['Bean Type'].sort_values().unique()\n",
    "#We can see there are derivations of certain types, there are values of '\\xa0', and values of nan. No spelling errors sighted.\n",
    "\n",
    "#Check the spelling of Broad Bean Origin values.\n",
    "df1['Broad Bean Origin'].sort_values().unique()\n",
    "#There are some entries that are continents and not countries. Would the exploration be better addressed if explored via coninent instead of country?\n",
    "\n",
    "df1[df1['Broad Bean Origin'].str.len()==1]['Specific Bean Origin or Bar Name'].unique()\n",
    "#We can see that some of our responses are blends or blend types. This may helpful for determining the missing values in the Bean Type column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
